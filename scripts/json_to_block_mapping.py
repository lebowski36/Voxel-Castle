#!/usr/bin/env python3
"""
JSON to BLOCK_MAPPING Bridge Script
Converts the new unified JSON block data to the legacy BLOCK_MAPPING format.
This allows testing atlas generation with the new data while preserving the working system.
"""

import json
import os
import sys
from pathlib import Path
from typing import Dict, Any

def load_unified_block_data(data_dir: str) -> Dict[str, Any]:
    """Load all block data from the unified JSON format"""
    data_dir = Path(data_dir)
    blocks_dir = data_dir / "blocks"
    index_file = blocks_dir / "_index.json"
    
    if not index_file.exists():
        raise FileNotFoundError(f"Index file not found: {index_file}")
    
    # Load index
    with open(index_file, 'r') as f:
        index_data = json.load(f)
    
    all_blocks = {}
    
    # Load each category file
    categories = index_data.get('metadata', {}).get('categories', {})
    for category_name, category_info in categories.items():
        file_path = blocks_dir / category_info['file']
        
        if not file_path.exists():
            print(f"Warning: Category file not found: {file_path}")
            continue
            
        with open(file_path, 'r') as f:
            category_data = json.load(f)
            
        # Extract blocks from this category
        blocks = category_data.get('blocks', {})
        for block_name, block_data in blocks.items():
            if not block_name.startswith('_'):  # Skip placeholders
                all_blocks[block_name] = block_data
                
    return all_blocks

def convert_to_block_mapping(blocks_data: Dict[str, Any]) -> Dict[int, Dict[str, str]]:
    """Convert unified block data to legacy BLOCK_MAPPING format"""
    block_mapping = {}
    
    for block_name, block_data in blocks_data.items():
        block_id = block_data.get('id')
        texture_info = block_data.get('texture_info', {})
        generation = texture_info.get('generation', {})
        
        if block_id is not None:
            # Create legacy format entry
            legacy_entry = {
                'type': generation.get('type', 'unknown'),
                'subtype': generation.get('subtype', 'unknown')
            }
            
            # Add any additional parameters from the generation section
            parameters = generation.get('parameters', {})
            legacy_entry.update(parameters)
            
            block_mapping[block_id] = legacy_entry
            
    return block_mapping

def generate_block_mapping_file(block_mapping: Dict[int, Dict[str, str]], output_file: str):
    """Generate a Python file with the BLOCK_MAPPING dictionary"""
    
    # Sort by block ID for consistent output
    sorted_mapping = dict(sorted(block_mapping.items()))
    
    content = '''#!/usr/bin/env python3
"""
Generated BLOCK_MAPPING from unified JSON data
This file is auto-generated by json_to_block_mapping.py
"""

# Block type classification for texture generation (GENERATED)
BLOCK_MAPPING = {
'''
    
    for block_id, mapping in sorted_mapping.items():
        type_val = mapping['type']
        subtype_val = mapping['subtype']
        content += f"    {block_id}: {{'type': '{type_val}', 'subtype': '{subtype_val}'}},\n"
    
    content += "}\n"
    
    with open(output_file, 'w') as f:
        f.write(content)

def compare_mappings(old_mapping: Dict[int, Dict[str, str]], new_mapping: Dict[int, Dict[str, str]]):
    """Compare old and new BLOCK_MAPPING for differences"""
    print("\nüîç Comparing BLOCK_MAPPING formats...")
    
    all_ids = set(old_mapping.keys()) | set(new_mapping.keys())
    
    missing_in_new = []
    missing_in_old = []
    differences = []
    matches = 0
    
    for block_id in sorted(all_ids):
        if block_id not in new_mapping:
            missing_in_new.append(block_id)
        elif block_id not in old_mapping:
            missing_in_old.append(block_id)
        else:
            old_entry = old_mapping[block_id]
            new_entry = new_mapping[block_id]
            
            if old_entry != new_entry:
                differences.append({
                    'id': block_id,
                    'old': old_entry,
                    'new': new_entry
                })
            else:
                matches += 1
    
    # Report results
    print(f"   ‚úÖ Matching entries: {matches}")
    
    if missing_in_new:
        print(f"   ‚ùå Missing in JSON data: {len(missing_in_new)} blocks")
        for block_id in missing_in_new[:5]:  # Show first 5
            print(f"      ‚Ä¢ Block ID {block_id}: {old_mapping[block_id]}")
        if len(missing_in_new) > 5:
            print(f"      ‚Ä¢ ... and {len(missing_in_new) - 5} more")
    
    if missing_in_old:
        print(f"   üìù New in JSON data: {len(missing_in_old)} blocks")
        for block_id in missing_in_old[:5]:  # Show first 5
            print(f"      ‚Ä¢ Block ID {block_id}: {new_mapping[block_id]}")
        if len(missing_in_old) > 5:
            print(f"      ‚Ä¢ ... and {len(missing_in_old) - 5} more")
    
    if differences:
        print(f"   ‚ö†Ô∏è  Different entries: {len(differences)}")
        for diff in differences[:3]:  # Show first 3
            print(f"      ‚Ä¢ Block ID {diff['id']}:")
            print(f"        Old: {diff['old']}")
            print(f"        New: {diff['new']}")
        if len(differences) > 3:
            print(f"      ‚Ä¢ ... and {len(differences) - 3} more differences")
    
    return len(missing_in_new) == 0 and len(differences) == 0

def load_current_block_mapping(create_atlas_file: str) -> Dict[int, Dict[str, str]]:
    """Extract BLOCK_MAPPING from the current create_atlas.py file"""
    # This is a simplified extraction - in practice we might need to import the module
    # For now, let's assume we can import it
    try:
        sys.path.insert(0, os.path.dirname(create_atlas_file))
        import create_atlas
        return create_atlas.BLOCK_MAPPING
    except ImportError as e:
        print(f"Warning: Could not import current BLOCK_MAPPING: {e}")
        return {}

def main():
    if len(sys.argv) < 2:
        print("Usage: python json_to_block_mapping.py <data_directory> [output_file]")
        print("Example: python json_to_block_mapping.py data block_mapping_generated.py")
        sys.exit(1)
    
    data_dir = sys.argv[1]
    output_file = sys.argv[2] if len(sys.argv) > 2 else "block_mapping_generated.py"
    
    try:
        print("üîÑ Converting JSON block data to BLOCK_MAPPING format...")
        
        # Load unified block data
        blocks_data = load_unified_block_data(data_dir)
        print(f"   üìñ Loaded {len(blocks_data)} blocks from JSON data")
        
        # Convert to legacy format
        block_mapping = convert_to_block_mapping(blocks_data)
        print(f"   üîÑ Converted {len(block_mapping)} entries to BLOCK_MAPPING format")
        
        # Generate output file
        generate_block_mapping_file(block_mapping, output_file)
        print(f"   üíæ Generated {output_file}")
        
        # Compare with current BLOCK_MAPPING if available
        current_mapping = load_current_block_mapping("create_atlas.py")
        if current_mapping:
            is_compatible = compare_mappings(current_mapping, block_mapping)
            if is_compatible:
                print("\n‚úÖ JSON data is fully compatible with current BLOCK_MAPPING!")
            else:
                print("\n‚ö†Ô∏è  JSON data has differences from current BLOCK_MAPPING")
                print("    This is expected during migration - review differences above")
        
        print(f"\nüéØ Next steps:")
        print(f"   1. Review the generated {output_file}")
        print(f"   2. Test atlas generation with: python create_atlas.py")
        print(f"   3. Compare output atlases for visual consistency")
        
    except Exception as e:
        print(f"‚ùå Error: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
